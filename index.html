<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Huan Wang's Website</title>

  <meta name="author" content="Huan Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <!-- Bio -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Huan Wang</name>
                  </p>
                  <p>
                    Welcome to my webpage! My name is Huan Wang (Chinese: 王欢. My first name means "happiness or joy"</i> in Chinese, a simple and
                    ultimate wish from my parents). 
                    
                    I am now a 4th-year Ph.D. candidate at <a
                      href="https://web.northeastern.edu/smilelab/">SMILE Lab</a>, Northeastern University (Boston,
                    USA), advised by Prof. <a href="http://www1.ece.neu.edu/~yunfu/">Yun (Raymond) Fu</a>. Before that,
                    I received my M.S. (2019) and B.E. (2016) degrees from Zhejiang University (Hangzhou, China), advised by Prof. <a href="https://person.zju.edu.cn/en/huhaoji">Haoji Hu</a>. During
                    2018 summer, I visited <a href=http://vllab.ucmerced.edu/>VLLab</a> at University of California, Merced,
                    luckily working with Prof. <a href=http://faculty.ucmerced.edu/mhyang/>Ming-Hsuan Yang</a>. 
                    
                    I also actively collaborate with fatanstic industrial researchers from Snap / MERL / Meta / Alibaba Group, etc.
                  </p>

                  <p>
                    My research works orbit <a href=https://github.com/MingSun-Tse/EfficientDNNs><b>Efficient Deep Learning</b></a> (a.k.a. <b>Model Compression</b>), spanning the most common image classifcation task (<a href=https://github.com/MingSun-Tse/Regularization-Pruning>GReg</a>, <a href=https://github.com/MingSun-Tse/Awesome-Pruning-at-Initialization>Pruning-at-Initialization Survey</a>, <a href=https://github.com/MingSun-Tse/TPP>TPP</a>) to neural style transfer (<a href=https://github.com/MingSun-Tse/Collaborative-Distillation>Collaborative-Distillation</a>, single image super-resolution (<a href=https://github.com/MingSun-Tse/ASSL>ASSL/GASSL</a>, <a href=https://github.com/MingSun-Tse/SRP>SRP</a>) and 3D novel view synthesis / NeRF / NeLF (<a href=https://snap-research.github.io/R2L/>R2L</a>, <a href=https://github.com/snap-research/MobileR2L>MobileR2L</a>).
                  </p>
                  
                  <p>
                  I do my best towards <a href=https://github.com/MingSun-Tse/smilelogging>easily reproducible</a> research.
                  </p>


                  <p style="text-align:center">
                    <a href="https://scholar.google.com/citations?user=0-On0y4AAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/mingsun-tse">GitHub</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/huanwang-zju/">LinkedIn</a> &nbsp/&nbsp
                    <a href="https://twitter.com/huanwang_zju">Twitter</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:25%;max-width:40%">
                  <a href="images/profile_v2.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/profile_v2.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>


          <!-- News -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <ul style=“list-style-type:square”>
                    <li> 2023/05: <b>[Talk]</b> Give a talk at <a href="https://zjui.intl.zju.edu.cn/en">ZJUI</a> on the recent advances in efficient neural light field (NeLF), featuring our two recent NeLF papers (<a href="https://snap-research.github.io/R2L/">R2L</a> and <a href="https://snap-research.github.io/MobileR2L/">MobileR2L</a>). [<a href="files/Talk@ZJUI-20230530.pdf">Slides</a>] </li>
                    <li> 2023/05: <b>[Award]</b> Recognized as <b>CVPR'23 Outstanding Reviewer</b> (<font color='red'>3.3%</font>). Thanks to <a href=https://cvpr2023.thecvf.com/>CVPR</a> and the ACs!</li>
                    <li> 2023/04: <b>[TPAMI'23]</b> Extension of our NeurIPS'21 spotlight paper
                      <a href=https://openreview.net/pdf?id=zAuDbrHC6fq>ASSL</a>, "<a href=https://ieeexplore.ieee.org/abstract/document/10106130>Global Aligned Structured Sparsity Learning for Efficient Image Super-Resolution</a>", is accepted by <a href=https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34>TPAMI</a> (IF=24.31). Code will be relased to the
                      <a href=https://github.com/MingSun-Tse/ASSL>same repo</a>.</li>
                    <li> 2023/03: <b>[Award]</b> Received ICLR'23 travel award. Thanks to <a href=https://iclr.cc>ICLR</a>!</li>
                    <li> 2023/02: <b>[CVPR'23]</b> 2 papers accepted by CVPR'23: (1) <a href=https://ArXiv.org/abs/2212.08057>MobileR2L</a> [<a href=https://github.com/snap-research/MobileR2L>Code</a>]
                      , congrats to <a href=https://www.linkedin.com/in/junli-cao-5165b41a1>Junli</a>! MobileR2L is a <i>blazing fast🚀</i> neural rendering model designed for mobile devices: It can render <b>1008x756</b> images at <b>56fps</b> on <b>iPhone13</b>. (2) <a href="https://ArXiv.org/abs/2303.14817">Frame Flexible
                      Network</a> [<a href=https://github.com/BeSpontaneous/FFN-pytorch>Code</a>], congrats to <a href=https://bespontaneous.github.io/homepage>Yitian</a>!</li>
                    <li> 2023/01: <b>[ICLR'23]</b> 2 papers accpeted by ICLR'23: <a href=https://openreview.net/forum?id=AZFvpnnewr>Trainabaility Preserveing Neural
                      Pruning (TPP)</a> and <a href=https://openreview.net/forum?id=awnvqZja69>Image as Set of Points</a>
                      (<font color='red'>Oral, top-5%</font>).</li>
                    <li> 2023/01: <b>[Internship'23]</b> Start part-time internship at Snap, luckily working with
                      the <a href=https://research.snap.com/team/category/creative-vision.html>Creative Vision</a> team again.</li>
                    <li> 2023/01: <b>[Preprint]</b> 🔥Check out our preprint work that deciphers the <i>so confusing</i>
                      benchmark
                      situation in neural network (filter) pruning: <a href=https://ArXiv.org/abs/2301.05219>Why is the State of Neural Network Pruning so Confusing? On the Fairness, Comparison Setup, and Trainability in Network Pruning</a>
                      [<a href=https://github.com/mingsun-tse/why-the-state-of-pruning-so-confusing>Code</a>]. Also give a talk @UT Austin about this work. Thanks for the warm invitation from Dr. <a href="https://shiweiliuiiiiiii.github.io/">Shiwei Liu</a> and Prof. <a href=https://express.adobe.com/page/CAdrFMJ9QeI2y>Atlas Wang!</li>
                    <li> 2022/10: <b>[Award]</b> Received NeurIPS'22 Scholar Award. Thanks to <a
                        href="https://nips.cc/">NeurIPS</a>!</li>
                    <li> 2022/09: <b>[NeurIPS'22]</b> 3 papers accepted by NeurIPS'22: One under my lead (which was my 1st
                      internship work at MERL in 2020 summer. Rejected 4 times. Now finally I close the loop. Thanks to
                      my co-authors and the reviewers!), two collaborations. Code: <a
                        href="https://huanwang.tech/Good-DA-in-KD/">Good-DA-in-KD</a>, <a
                        href="https://github.com/yueb17/PEMN">PEMN</a>, <a
                        href="https://github.com/BeSpontaneous/AFNet-pytorch">AFNet</a>.</li>
                    <li> 2022/09: <b>[TIP'22]</b> One journal paper <a
                        href="https://ieeexplore.ieee.org/abstract/document/9944689">"Semi-supervised Domain Adaptive
                        Structure Learning"</a> accepted by TIP. Congtrats to <a href=https://canqin.tech/>Can</a>!</li>
                    <li> 2022/07: <b>[ECCV'22]</b> We present the first residual MLP network to represent <b>neural
                        light
                        field
                        (NeLF)</b> for efficient novel view synthesis. Check our <a
                        href="https://snap-research.github.io/R2L/">webpage</a> and <a
                        href="https://ArXiv.org/abs/2203.17261">ArXiv</a>!</li>
                    <li> 2022/04: <b>[IJCAI'22]</b> We offer the very first survey paper on <b>Pruning at
                        Initialization</b>,
                        accepted by IJCAI'22 [<a href="https://ArXiv.org/abs/2103.06460">ArXiv</a>] [<a
                          href="https://github.com/MingSun-Tse/Awesome-Pruning-at-Initialization">Paper Collection</a>].
                    </li>
                    <li> 2022/01: <b>[ICLR'22]</b> Two papers on neural network sparsity accepted by ICLR'22. One is
                      about
                      efficient image super-resolution (<a href="https://openreview.net/forum?id=AjGC97Aofee">SRP</a>),
                      the other about lottery ticket hypothsis (<a
                        href="https://openreview.net/forum?id=fOsN52jn25l">DLTH</a>).</li>
                    <li> 2021/09: <b>[NeurIPS'21]</b> One paper on efficient image super-resolution is accepted by
                      NeurIPS'21
                      as a <font color='red'>Spotlight (<3%)</font> paper! [<a href="https://github.com/MingSun-Tse/ASSL">Code</a>]</li>
                    <li> 2021/06: <b>[Internship'21]</b> Start summer internship at Snap Inc., working with the
                      fantastic <a href="https://research.snap.com/team/category/creative-vision.html">Creative
                        Vision</a> team.</li>
                    <li> 2021/01: <b>[ICLR'21]</b> One paper about neural network pruning accepted by ICLR'21 as
                      poster. [<a href="https://ArXiv.org/abs/2012.09243">ArXiv</a>] [<a
                        href="https://github.com/MingSun-Tse/Regularization-Pruning">Code</a>]</li>
                    <li> 2020/06: <b>[Internship'20]</b> Start summer internship at MERL, working with Dr. <a
                        href="https://scholar.google.com/citations?user=h-V4QaMAAAAJ&hl=en&oi=ao">Mike Jones</a> and
                      Dr.
                      <a href="http://suhaslohit.github.io">Suhas Lohit</a>. (2022/09 Update: Finally, paper of this
                      project accpeted by NeurIPS'22 -- two good years have passed, thank God..!)</li>
                    <li> 2020/02: <b>[CVPR'20]</b> One paper about model compression for ultra-resolution neural
                      style
                      transfer "<a href=https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_Collaborative_Distillation_for_Ultra-Resolution_Universal_Style_Transfer_CVPR_2020_paper.html>Collaborative Distillation for Ultra-Resolution Universal Style Transfer</a>" is accepted by CVPR'20 [<a
                        href="https://github.com/MingSun-Tse/Collaborative-Distillation">Code</a>].
                    <li> 2020/01: <b>[MLSys'20]</b> 2019 summer intern paper accepted by <a
                        href="https://mlsys.org/">MLSys
                        2020</a>. (Project: <a href="https://github.com/alibaba/MNN">MNN</a> from Alibaba, one of
                      the
                      <i>fastest</i> mobile AI engines on this planet. Welcome trying!)</li>
                    <li> 2019/12: <b>[JSTSP'19]</b> One journal paper "<a href=https://ieeexplore.ieee.org/abstract/document/8937758>Structured Pruning for Efficient Convolutional Neural Networks via Incremental Regularization</a>" accepted by <a
                        href="https://signalprocessingsociety.org/publications-resources/ieee-journal-selected-topics-signal-processing">IEEE
                        JSTSP</a>.</li>
                    <li> 2019/09: Join <a
                      href="https://web.northeastern.edu/smilelab/">SMILE Lab</a> at Northeastern University (Boston, USA) to pursue my Ph.D. degree.</li>
                    <li> 2019/07: <b>[Internship'19]</b> Start summer internship at Taobao of Alibaba Group (
                      Hangzhou,
                      China).</li>
                    <li> 2019/06: Graduate with M.Sc. degree from Zhejiang University (Hangzhou, China).</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>My Research</heading>
                  <heading>[</heading><a href=https://scholar.google.com/citations?user=0-On0y4AAAAJ&hl=en><heading>Google Scholar</heading></a><heading>]</heading>
                </td>
              </tr>
            </tbody>
          </table>

          
          <!-- Projects / Papers -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr style="border-collapse: separate; border-spacing:10px">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/plot_Fairness_overview_for_Arxiv_v2.png"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href="https://github.com/MingSun-Tse/Why-the-State-of-Pruning-so-Confusing">Why is the State of Neural Network Pruning so Confusing? On the Fairness, Comparison Setup, and Trainability in Network Pruning</a></b><br>
                  <b>Huan Wang</b>, Can Qin, Yue Bai, Yun Fu<br>
                  <b><i>Preprint</i></b>, 2023<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <a href="https://ArXiv.org/abs/2301.05219">ArXiv</a> <br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <a href="https://github.com/MingSun-Tse/Why-the-State-of-Pruning-so-Confusing">Code</a><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:10px">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/TPAMI23_GASSL.png"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10106130"><b>Global Aligned Structured Sparsity Learning for Efficient Image Super-Resolution</b></a><br>
                  <b>Huan Wang</b>*, Yulun Zhang*, Can Qin, Luc Van Gool, Yun Fu (*Equal Contribution)<br>
                  <b><i>TPAMI</i></b>, 2023<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10106130">PDF</a> <br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <a href="https://github.com/MingSun-Tse/ASSL">Code</a><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:10px">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/MobileR2L.png"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <a href="https://snap-research.github.io/MobileR2L"><b>Real-Time Neural Light Field on Mobile Devices</b></a><br>
                  Junli Cao, <b>Huan Wang</b>, Pavlo Chemerys, Vladislav Shakhrai, Ju Hu, Yun Fu, Denys Makoviichuk,
                  Sergey Tulyakov, Jian Ren<br>
                  In <b><i>CVPR</i></b>, 2023<br>
                  <img
                    src="images/project_icon.png"
                    width="15" height="15" hspace="2">
                  <a href="https://snap-research.github.io/MobileR2L/">Project Webpage</a> <br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <a href="https://ArXiv.org/abs/2212.08057">ArXiv</a> <br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <a href="https://github.com/snap-research/MobileR2L">Code</a><br>
                </td>
              </tr>
              <!-- bgcolor="#E0E0E0" -->


              <tr style="border-collapse: separate; border-spacing:10px;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/ICLR23_TPP.png"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://ArXiv.org/abs/2207.12534>Trainability Preserving Neural Pruning</a></b><br>
                  <b>Huan Wang</b>, Yun Fu<br>
                  In <b><i>ICLR</i></b>, 2023<br>
                  <img
                    src="images/openreview_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://openreview.net/forum?id=AZFvpnnewr">OpenReivew</a></span><br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://ArXiv.org/abs/2207.12534">ArXiv</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/mingsun-tse/tpp">PyTorch Code</a></span><br>
                </td>
              </tr>

              
              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/ICLR23_CoC.jpeg"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://ArXiv.org/abs/2303.01494>Image as Set of Points</b></a><br>
                  Xu Ma, Yuqian Zhou, <b>Huan Wang</b>, Can Qin, Bin Sun, Chang Liu, Yun Fu<br>
                  
                  In <b><i>ICLR</i></b> (<font color='red'>Oral, 5%</font>), 2023<br>
                  <img
                    src="images/project_icon.png"
                    width="15" height="15" hspace="2">
                  <a href="https://ma-xu.github.io/Context-Cluster/">Project Webpage</a> <br>
                  <img
                    src="images/openreview_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://openreview.net/forum?id=awnvqZja69">OpenReview</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://anonymous.4open.science/r/ContextCluster/README.md">PyTorch Code</a></span><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img src="images/KD_DA.png"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://mingsun-tse.github.io/Good-DA-in-KD>What Makes a "Good" Data Augmentation in Knowledge Distillation -- A Statistical Perspective</a></b><br>
                  <b>Huan Wang</b>, Suhas Lohit, Mike Jones, Yun Fu<br>
                  
                  In <b><i>NeurIPS</i></b>, 2022<br>
                  <img
                    src="images/project_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://mingsun-tse.github.io/Good-DA-in-KD">Project Webpage</a></span><br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://ArXiv.org/abs/2012.02909">ArXiv</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/MingSun-Tse/Good-DA-in-KD">PyTorch Code</a></span><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/Yue_NIPS22_PEMN.svg"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://yueb17.github.io/PEMN>Parameter-Efficient Masking Networks</a></b><br>
                  Yue Bai, <b>Huan Wang</b>, Xu Ma, Yitian Zhang, Zhiqiang Tao, Yun Fu<br>
                  In <b><i>NeurIPS</i></b>, 2022<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://ArXiv.org/abs/2210.06699">ArXiv</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/yueb17/PEMN">PyTorch Code</a></span><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/Yitian_NIPS22_AFNet.svg"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <a href=https://ArXiv.org/abs/2211.09992>Look More but Care Less in Video Recognition</a><br>
                  Yitian Zhang, Yue Bai, <b>Huan Wang</b>, Yi Xu, Yun Fu<br>
                  In <b><i>NeurIPS</i></b>, 2022<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://ArXiv.org/abs/2211.09992">ArXiv</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/BeSpontaneous/AFNet-pytorch">PyTorch Code</a></span><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img src="images/R2L.png"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://snap-research.github.io/R2L>R2L: Distilling Neural Radiance Field to Neural Light Field for Efficient Novel View
                    Synthesis</a></b><br>
                  <b>Huan Wang</b>, Jian Ren, Zeng Huang, Kyle Olszewski, Menglei Chai, Yun Fu, Sergey Tulyakov<br>
                  In <b><i>ECCV</i></b>, 2022<br>
                  <img
                    src="images/project_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://snap-research.github.io/R2L/">Project Webpage</a></span><br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://ArXiv.org/abs/2203.17261">ArXiv</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/snap-research/R2L">PyTorch Code</a></span><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/emerging_pruning.png"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <a href=https://ArXiv.org/abs/2103.06460>Recent Advances on Neural Network Pruning at Initialization</a><br>
                  <b>Huan Wang</b>, Can Qin, Yue Bai, Yulun Zhang, Yun Fu<br>
                  In <b><i>IJCAI</i></b>, 2022<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://ArXiv.org/abs/2103.06460">ArXiv</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/MingSun-Tse/Awesome-Pruning-at-Initialization">Paper Collection</a></span><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/ICLR22_SRP.png"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://openreview.net/forum?id=AjGC97Aofee>Learning Efficient Image Super-Resolution Networks via Structure-Regularized Pruning</a></b><br>
                  <b>Huan Wang*</b>, Yulun Zhang*, Can Qin, Yun Fu (*Equal Contribution)<br>
                  In <b><i>ICLR</i></b>, 2022<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://openreview.net/forum?id=AjGC97Aofee">Open Review</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/MingSun-Tse/SRP">PyTorch Code</a></span><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/ICLR22_DLTH.png"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://ArXiv.org/abs/2203.04248>Dual Lottery Ticket Hypothesis</a></b><br>
                  Yue Bai, <b>Huan Wang</b>, Zhiqiang Tao, Kunpeng Li, Yun Fu<br>
                  In <b><i>ICLR</i></b>, 2022<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://openreview.net/forum?id=fOsN52jn25l">Open Review</a></span>, <span><a
                      href="https://ArXiv.org/abs/2203.04248">ArXiv</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/yue17/DLTH">PyTorch Code</a></span><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/NIPS21_ASSL.png"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://openreview.net/pdf?id=zAuDbrHC6fq>Aligned Structured Sparsity Learning for Efficient Image Super-Resolution</a></b><br>
                  <b>Huan Wang*</b>, Yulun Zhang*, Can Qin, Yun Fu (*Equal Contribution)<br>
                  In <b>NeurIPS</b> (<font color='red'>Spotlight, <3%</font>), 2021<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://openreview.net/pdf?id=zAuDbrHC6fq">Camera Ready</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/MingSun-Tse/ASSL">PyTorch Code</a></span><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/L1norm_vs_iter.png"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://ArXiv.org/abs/2012.09243>Neural Pruning via Growing Regularization</a></b><br>
                  <b>Huan Wang</b>, Can Qin, Yulun Zhang, Yun Fu<br>
                  In <b><i>ICLR</i></b>, 2021<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://ArXiv.org/abs/2012.09243">ArXiv</a></span>, <span><a
                      href="https://openreview.net/forum?id=o966_Is_nPA&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2021%2FConference%2FAuthors%23your-submissions)">OpenReview</a></span>
                  <br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/MingSun-Tse/Regularization-Pruning">PyTorch Code</a></span><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/collaborative_distillation.jpg"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://ArXiv.org/abs/2003.08436>Collabrotive Distillation for Ultra-Resolution Universal Style Transfer</a></b><br>
                  <b>Huan Wang</b>, Yijun Li, Yuehai Wang, Haoji Hu, Ming-Hsuan Yang<br>
                  In <b><i>CVPR</i></b>, 2020<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://ArXiv.org/abs/2003.08436">ArXiv</a>, <a
                      href="https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_Collaborative_Distillation_for_Ultra-Resolution_Universal_Style_Transfer_CVPR_2020_paper.html">Camera
                      Ready</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/MingSun-Tse/Collaborative-Distillation">PyTorch Code</a></span><br>
                </td>
              </tr>

              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img src="images/MNN.jpg"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://ArXiv.org/abs/2002.12418>MNN: A Universal and Efficient Inference Engine</a></b><br>
                  Xiaotang Jiang, <b>Huan Wang</b>, Yiliu Chen, Ziqi Wu, et al<br>
                  In <b><i>MLSys</i></b> (<font color='red'>Oral</font>), 2020<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://ArXiv.org/abs/2002.12418">ArXiv</a></span><br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/alibaba/MNN">Code</a></span>
                </td>
              </tr>


              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <img
                    src="images/IncReg.jpeg"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://ArXiv.org/abs/1804.09461>Structured Pruning for Efficient ConvNets via Incremental Regularization</a></b><br>
                  <b>Huan Wang</b>, Xinyi Hu, Qiming Zhang, Yuehai Wang, Lu Yu, Haoji Hu<br>
                  In <b><i>NeurIPS Workshop</i></b>, 2018; <b><i>IJCNN</i></b>, 2019 (<font color='red'>Oral</font>); Journal
                  extension to <b><i>IEEE JSTSP</i></b>, 2019<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2"> <span><a href="https://ArXiv.org/abs/1811.08390">NeurIPS
                      Workshop</a></span>,
                  <span><a href="https://ArXiv.org/abs/1804.09461">IJCNN</a></span>,
                  <span><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8937758">JSTSP</a></span> <br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/alibaba/MNN">Caffe Code</a></span>
                </td>
              </tr>


              <tr style="border-collapse: separate; border-spacing:none;">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/SPP.jpeg"
                    width="320" />
                </td>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <b><a href=https://ArXiv.org/abs/1709.06994>Structured Probabilistic Pruning for Convolutional Neural Network Acceleration</a></b><br>
                  <b>Huan Wang</b>*, Qiming Zhang*, Yuehai Wang, Haoji Hu (*Equal Contribution)<br>
                  In <b><i>BMVC</i></b>, 2018 (<font color='red'>Oral</font>)<br>
                  <img
                    src="images/pdf_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://ArXiv.org/abs/1709.06994">ArXiv</a>, <a
                      href="http://bmvc2018.org/contents/papers/0870.pdf">Camera Ready</a></span> <br>
                  <img
                    src="images/github_icon.png"
                    width="15" height="15" hspace="2">
                  <span><a href="https://github.com/MingSun-Tse/Caffe_IncReg">Caffe Code</a></span>
                </td>
              </tr>

            </tbody>
          </table>
          
          <!-- Talks -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tbody>
              <tr>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <heading>Talks</heading>
                    <ul style=“list-style-type:square”>
                    <li>[05/30/2023] Prof. <a href="https://scholar.google.com/citations?user=h602wLIAAAAJ&hl=en">Zuozhu Liu</a>'s Group @ZJUI: Recent Advances on Efficient Neural Light Field [<a href="files/Talk@ZJUI-20230530.pdf">Slides</a>]</li>
                    <li>[01/06/2023] <a href=https://vita-group.github.io/index.html>VITA Group</a> @UT Austin: <a href=https://ArXiv.org/abs/2301.05219>Why is the State of Neural Network Pruning so Confusing? On the Fairness, Comparison Setup, and Trainability in Network Pruning</a> [Slides]</li>
                    <li>[09/30/2021] <a href=https://db.khoury.northeastern.edu/activities>Data Lab</a> @NEU: <a href=https://github.com/MingSun-Tse/Regularization-Pruning>Neural Pruning via Growing Regularization (ICLR'21)</a> [Slides]</li>
                    </ul>
                </td>
              </tr>
            </tbody>
          </table>


          <!-- Professional Services -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tbody>
              <tr>
                <td style="padding:10px; border-collapse: collapse; border: none;">
                  <heading>Professional Services</heading>
                  <ul style=“list-style-type:square”>
                  <li>Journal Reviewer: IJCV, TIP, TNNLS, PR, JSTSP, Neurocomputing, etc.</li>
                  <li>Conference Reviewer: CVPR'22, ECCV'22, ICML'22, NeurIPS'22, ICLR'22, AAAI'23, IJCAI'23, CVPR'23, MLSys'23, ICCV'23, NeurIPS'23 etc.</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>

              <!-- <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
                <td width="75%" valign="center">
                  <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                  <br>
                  <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member,
                    CVPR 2021</a>
                  <br>
                  <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                  <br>
                  <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/cs188.jpg" alt="cs188">
                </td>
                <td width="75%" valign="center">
                  <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor,
                    CS188 Spring 2011</a>
                  <br>
                  <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor,
                    CS188 Fall 2010</a>
                  <br>
                  <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd
                    Edition</a>
                </td>
              </tr>


              <tr>
                <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                  <heading>Basically <br> Blog Posts</heading>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://ArXiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                  <br>
                  <a href="https://ArXiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain
                    Functions</a>
                  <br>
                  <a href="https://ArXiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                </td>
              </tr> -->


            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    (Stolen from <a href="https://jonbarron.info/">Jon Barron</a>)
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>


<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=500&t=tt&d=U-QrHQYlYWMu0cG0M0Eo37wKSkKKLRkYr4Mx18EP-t4'>
</script>

</body>
</html>